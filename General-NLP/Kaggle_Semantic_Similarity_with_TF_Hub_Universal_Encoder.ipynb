{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Kaggle - Semantic Similarity with TF-Hub Universal Encoder",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/IsraelAbebe/Personal-Projects-and-Exercises/blob/master/General-NLP/Kaggle_Semantic_Similarity_with_TF_Hub_Universal_Encoder.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "lVjNK8shFKOC",
        "colab": {}
      },
      "source": [
        "# Install the latest Tensorflow version.\n",
        "!pip3 install --quiet \"tensorflow>=1.7\"\n",
        "# Install TF-Hub.\n",
        "!pip3 install --quiet tensorflow-hub\n",
        "!pip3 install --quiet seaborn"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "63Pd3nJnTl-i"
      },
      "source": [
        "More detailed information about installing Tensorflow can be found at [https://www.tensorflow.org/install/](https://www.tensorflow.org/install/)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "MSeY-MUQo2Ha",
        "colab": {}
      },
      "source": [
        "from absl import logging\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import pandas as pd\n",
        "import re\n",
        "import seaborn as sns\n",
        "\n",
        "from textblob import TextBlob\n",
        "\n",
        "\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "from tensorflow.keras.optimizers import Adam,RMSprop,Adagrad\n",
        "from tensorflow.keras.layers import Dense, Input, BatchNormalization, Dropout, Concatenate\n",
        "from tensorflow.keras.models import Model, Sequential\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from tensorflow.keras import layers"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sfpO-z77ydR9",
        "colab_type": "code",
        "outputId": "d6e759c8-43fa-472a-ea5a-c0f9fae2693e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive/')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "zwty8Z6mAkdV",
        "colab": {}
      },
      "source": [
        "module_url = \"https://tfhub.dev/google/universal-sentence-encoder-large/3\" #@param [\"https://tfhub.dev/google/universal-sentence-encoder/2\", \"https://tfhub.dev/google/universal-sentence-encoder-large/3\"]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Q8F4LNGFqOiq",
        "colab": {}
      },
      "source": [
        "# Import the Universal Sentence Encoder's TF Hub module\n",
        "embed = hub.Module(module_url)\n",
        "\n",
        "def get_sentiment(message):\n",
        "    result = TextBlob(message).sentiment.subjectivity\n",
        "    return result\n",
        "def get_sentiment2(message):\n",
        "    result = TextBlob(message).sentiment.polarity\n",
        "    return result+1\n",
        "# Reduce logging output.\n",
        "def get_sentese_embedding(messages):\n",
        "    logging.set_verbosity(logging.ERROR)\n",
        "\n",
        "    with tf.Session() as session:\n",
        "      session.run([tf.global_variables_initializer(), tf.tables_initializer()])\n",
        "      message_embeddings = session.run(embed(messages))\n",
        "\n",
        "      return message_embeddings"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8d6cXLJNvPNx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "paragraph = [\"Universal Sentence Encoder embeddings also support short paragraphs. \",\n",
        "    \"There is no hard limit on how long the paragraph is. Roughly, the longer \",\n",
        "    \"the more 'diluted' the embedding will be.\"]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vEZewAHiu4wb",
        "colab_type": "code",
        "outputId": "8a2f899f-5023-4206-996e-55a954986494",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "np.vectorize(get_sentiment2)(paragraph).reshape(-1,1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1.        ],\n",
              "       [0.99861111],\n",
              "       [1.5       ]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-XVT15NCpIDL",
        "colab_type": "code",
        "outputId": "2910d671-e8cd-4596-dd11-f5f18da12553",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "get_sentese_embedding(paragraph).shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3, 512)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ejY5OILbxHdz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def process_text(text):\n",
        "    text = text.encode('ascii', errors='ignore').decode()\n",
        "    text = text.lower()\n",
        "    text = re.sub(r'http\\S+', ' ', text)\n",
        "    text = re.sub(r'#+', ' ', text )\n",
        "    text = re.sub(r'@[A-Za-z0-9]+', ' ', text)\n",
        "    text = re.sub(r\"([A-Za-z]+)'s\", r\"\\1 is\", text)\n",
        "    text = re.sub(r\"\\'s\", \" \", text)     \n",
        "    text = re.sub(r\"\\'ve\", \" have \", text)\n",
        "    text = re.sub(r\"won't\", \"will not \", text)\n",
        "    text = re.sub(r\"isn't\", \"is not \", text)\n",
        "    text = re.sub(r\"can't\", \"can not \", text)\n",
        "    text = re.sub(r\"n't\", \" not \", text)\n",
        "    text = re.sub(r\"i'm\", \"i am \", text)\n",
        "    text = re.sub(r\"\\'re\", \" are \", text)\n",
        "    text = re.sub(r\"\\'d\", \" would \", text)\n",
        "    text = re.sub(r\"\\'ll\", \" will \", text)\n",
        "    text = re.sub('\\W', ' ', text)\n",
        "    text = re.sub(r'\\d+', ' ', text)\n",
        "    text = re.sub('\\s+', ' ', text)\n",
        "    text = text.strip()\n",
        "    return text"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tNy7UyADyIhS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train = pd.read_csv(\"gdrive/My Drive/dataset/train.csv\")\n",
        "test = pd.read_csv(\"gdrive/My Drive/dataset/test.csv\")\n",
        "submission = pd.read_csv(\"gdrive/My Drive/dataset/sample_submission.csv\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ecza_OOVyT2O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train['text'] = train.text.apply(lambda x: process_text(x))\n",
        "test['text'] = test.text.apply(lambda x: process_text(x))\n",
        "\n",
        "train['count'] = train.text.apply(lambda x: len(x.split()))\n",
        "test['count'] = test.text.apply(lambda x: len(x.split()))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-1l6lU17zBhD",
        "colab_type": "code",
        "outputId": "6c14d6a4-3dd0-42e7-b44f-a3ceb5b78f47",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "sentiments_list = np.vectorize(get_sentiment)(train.text.values).reshape(-1,1)\n",
        "sentiments_list2 = np.vectorize(get_sentiment2)(train.text.values).reshape(-1,1)\n",
        "print(sentiments_list.shape)\n",
        "\n",
        "test_sentiments_list = np.vectorize(get_sentiment)(test.text.values).reshape(-1,1)\n",
        "test_sentiments_list2 = np.vectorize(get_sentiment2)(test.text.values).reshape(-1,1)\n",
        "test_sentiments_list.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(7613, 1)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3263, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "adPCMhxvzNHQ",
        "colab_type": "code",
        "outputId": "57e00aa1-bf85-41e7-9169-52506865cd65",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "embeddings = get_sentese_embedding(train.text.values)\n",
        "print(embeddings.shape)\n",
        "\n",
        "test_embeddings = get_sentese_embedding(test.text.values)\n",
        "print(test_embeddings.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(7613, 512)\n",
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(3263, 512)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fxCr0lzQ-S0d",
        "colab_type": "code",
        "outputId": "a7bf24f0-52c2-4acf-d8f2-a9e689a41e2f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "embeddings[:,:100].shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(7613, 100)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dSP2P0HszUn3",
        "colab_type": "code",
        "outputId": "11dd0721-7920-48c7-cce7-a29698202936",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "final = pd.concat([pd.DataFrame(embeddings),pd.DataFrame(sentiments_list),pd.DataFrame(sentiments_list2),pd.DataFrame(train['count'].values)],axis=1)\n",
        "print(final.values.shape)\n",
        "\n",
        "test_final = pd.concat([pd.DataFrame(test_embeddings),pd.DataFrame(test_sentiments_list),pd.DataFrame(test_sentiments_list2),pd.DataFrame(test['count'].values)],axis=1)\n",
        "test_final.values.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(7613, 515)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3263, 515)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MUpvXzeu9sIu",
        "colab_type": "code",
        "outputId": "c411abaf-47c2-4924-817a-c51fd1fe0686",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "train_data = final.values\n",
        "train_labels = train.target.values\n",
        "\n",
        "\n",
        "test_data = test_final.values\n",
        "train_data.shape,train_labels.shape,test_data.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((7613, 515), (7613,), (3263, 515))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OMp2rku29dt7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# from sklearn.feature_selection import SelectKBest\n",
        "# from sklearn.svm import LinearSVC\n",
        "# from sklearn.feature_selection import SelectFromModel\n",
        "\n",
        "# lsvc = LinearSVC(C=0.01, penalty=\"l1\", dual=False).fit(train_data, train_labels)\n",
        "# model = SelectFromModel(lsvc, prefit=True)\n",
        "# train_data = model.transform(train_data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WrM39BIs9d3P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "169DQq9G9eAT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1-Yx7SL51rfZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xfiCuyUczuBW",
        "colab_type": "code",
        "outputId": "3f7e4baa-ac1d-43e1-bfbb-1e1e215c3b9a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 493
        }
      },
      "source": [
        "def build_model():\n",
        "    model = Sequential([\n",
        "        Input(shape=(515,)),\n",
        "        Dense(1024, activation='relu'),\n",
        "        BatchNormalization(),\n",
        "        Dropout(0.5),\n",
        "        Dense(512, activation='relu'),\n",
        "        BatchNormalization(),\n",
        "        Dropout(0.5),\n",
        "        Dense(128, activation='relu'),\n",
        "        BatchNormalization(),\n",
        "        Dropout(0.5),\n",
        "        Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "    model.compile(Adam(lr=0.0001), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    \n",
        "    return model\n",
        "\n",
        "model = build_model()\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_6\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_18 (Dense)             (None, 1024)              528384    \n",
            "_________________________________________________________________\n",
            "batch_normalization_12 (Batc (None, 1024)              4096      \n",
            "_________________________________________________________________\n",
            "dropout_12 (Dropout)         (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense_19 (Dense)             (None, 512)               524800    \n",
            "_________________________________________________________________\n",
            "batch_normalization_13 (Batc (None, 512)               2048      \n",
            "_________________________________________________________________\n",
            "dropout_13 (Dropout)         (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_20 (Dense)             (None, 128)               65664     \n",
            "_________________________________________________________________\n",
            "batch_normalization_14 (Batc (None, 128)               512       \n",
            "_________________________________________________________________\n",
            "dropout_14 (Dropout)         (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_21 (Dense)             (None, 1)                 129       \n",
            "=================================================================\n",
            "Total params: 1,125,633\n",
            "Trainable params: 1,122,305\n",
            "Non-trainable params: 3,328\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "63pEYWnN0NXP",
        "colab_type": "code",
        "outputId": "bd5475ce-4f71-4ea8-cba0-1abed792be8f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 510
        }
      },
      "source": [
        "checkpoint = ModelCheckpoint('model.h5', monitor='val_loss', save_best_only=True)\n",
        "callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)\n",
        "\n",
        "train_history = model.fit(\n",
        "    train_data, train_labels,\n",
        "    validation_split=0.01,\n",
        "    epochs=50,\n",
        "    callbacks=[checkpoint,callback],\n",
        "    batch_size=32\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 7536 samples, validate on 77 samples\n",
            "Epoch 1/50\n",
            "7536/7536 [==============================] - 1s 180us/sample - loss: 0.4409 - acc: 0.8166 - val_loss: 0.1825 - val_acc: 0.9221\n",
            "Epoch 2/50\n",
            "7536/7536 [==============================] - 1s 189us/sample - loss: 0.4405 - acc: 0.8121 - val_loss: 0.1783 - val_acc: 0.9351\n",
            "Epoch 3/50\n",
            "7536/7536 [==============================] - 1s 185us/sample - loss: 0.4376 - acc: 0.8141 - val_loss: 0.1732 - val_acc: 0.9351\n",
            "Epoch 4/50\n",
            "7536/7536 [==============================] - 1s 170us/sample - loss: 0.4247 - acc: 0.8183 - val_loss: 0.1780 - val_acc: 0.9481\n",
            "Epoch 5/50\n",
            "7536/7536 [==============================] - 1s 183us/sample - loss: 0.4196 - acc: 0.8259 - val_loss: 0.1778 - val_acc: 0.9221\n",
            "Epoch 6/50\n",
            "7536/7536 [==============================] - 1s 176us/sample - loss: 0.4187 - acc: 0.8174 - val_loss: 0.1636 - val_acc: 0.9481\n",
            "Epoch 7/50\n",
            "7536/7536 [==============================] - 1s 180us/sample - loss: 0.4081 - acc: 0.8280 - val_loss: 0.1692 - val_acc: 0.9351\n",
            "Epoch 8/50\n",
            "7536/7536 [==============================] - 1s 186us/sample - loss: 0.4050 - acc: 0.8295 - val_loss: 0.1618 - val_acc: 0.9610\n",
            "Epoch 9/50\n",
            "7536/7536 [==============================] - 1s 187us/sample - loss: 0.4049 - acc: 0.8259 - val_loss: 0.1606 - val_acc: 0.9481\n",
            "Epoch 10/50\n",
            "7536/7536 [==============================] - 1s 174us/sample - loss: 0.4023 - acc: 0.8260 - val_loss: 0.1664 - val_acc: 0.9481\n",
            "Epoch 11/50\n",
            "7536/7536 [==============================] - 1s 179us/sample - loss: 0.3932 - acc: 0.8292 - val_loss: 0.1707 - val_acc: 0.9221\n",
            "Epoch 12/50\n",
            "7536/7536 [==============================] - 1s 186us/sample - loss: 0.3906 - acc: 0.8313 - val_loss: 0.1628 - val_acc: 0.9481\n",
            "Epoch 13/50\n",
            "7536/7536 [==============================] - 1s 173us/sample - loss: 0.3918 - acc: 0.8339 - val_loss: 0.1665 - val_acc: 0.9351\n",
            "Epoch 14/50\n",
            "7536/7536 [==============================] - 1s 181us/sample - loss: 0.3889 - acc: 0.8339 - val_loss: 0.1652 - val_acc: 0.9610\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Krv4b_Zy1-7P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.load_weights('model.h5')\n",
        "test_pred = model.predict(test_data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2caJiLZV2Yuq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "submission['target'] = test_pred.round().astype(int)\n",
        "submission.to_csv('gdrive/My Drive/dataset/submission.csv', index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_0DWr3Mp3qsb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
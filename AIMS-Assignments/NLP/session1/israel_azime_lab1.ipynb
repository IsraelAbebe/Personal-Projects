{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h1 style=\"font-family:verdana;font-size:300%;text-align:center;background-color:#f2f2f2;color:#0d0d0d\">AMMI NLP - Part 1</h1>\n",
    "\n",
    "<h1 style=\"font-family:verdana;font-size:150%;text-align:Center;color:#993333\"> Lab 1: Introduction to text classification  </h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"font-family:verdana;font-size:150%;text-align:left;color:blue\">Section 1: Text Classification with Naive Bayes Classifier </h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### In this part you'll implement Naive Bayes classifier to classify the text. You need to build a model that predicts the langauge of the text given the words of the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XPLa9c7luXUt"
   },
   "outputs": [],
   "source": [
    "import io, sys, math, re\n",
    "from collections import defaultdict\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wrJwiEp0ulMr"
   },
   "outputs": [],
   "source": [
    "def load_data(filename):\n",
    "    '''\n",
    "    Parameters:\n",
    "    filename (string): path to file to be read\n",
    "    \n",
    "    Return: \n",
    "    List of tuples (explained in first question)\n",
    "    '''\n",
    "    fin = io.open(filename, 'r', encoding='utf-8')\n",
    "    data = []\n",
    "    for line in fin:\n",
    "        tokens = line.split()\n",
    "        data.append((tokens[0], tokens[1:]))\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "97xy70o7unLd",
    "outputId": "7716c51a-082c-40f8-f0c2-3a88216e990c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('__label__deu', ['Tom', 'ist', 'an', 'Kunst', 'völlig', 'uninteressiert.'])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = load_data(\"train1.txt\")\n",
    "data[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "t5NGgAyq_Kau"
   },
   "source": [
    "\n",
    "![for](images/1.png)\n",
    "\n",
    "![for](images/2.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "T7Z9pr0NupNK"
   },
   "outputs": [],
   "source": [
    "def count_words(data):\n",
    "    '''\n",
    "    Parameters:\n",
    "    \n",
    "    data is  list of [(label, words), (label, worlds), ......]\n",
    "    list of tuples in the shape (string, [list of strings]) )\n",
    "    \n",
    "    Returns: \n",
    "    \n",
    "    This function should return a dictionary containing the following:\n",
    "    { \n",
    "    # label_counts (python dictionary): \n",
    "         {label:  no. of times the label appeared },\n",
    "    # word_counts  (dictionary of dictionaries): \n",
    "         {label: {word: no. of times this word appeared with this label }},\n",
    "    # label_total (int): \n",
    "        total number of labels. (size of train data),\n",
    "    # word_total  (python dictionary) total number of words (from the entire corupus) of the particular label:\n",
    "          {label: no.of words}\n",
    "          \n",
    "          }\n",
    "    \n",
    "    '''\n",
    "    label_total = 0\n",
    "    word_total = defaultdict(lambda: 0)\n",
    "    label_counts = defaultdict(lambda: 0)\n",
    "    word_counts = defaultdict(lambda: defaultdict(lambda: 0.0))\n",
    "    \n",
    "    for example in data:\n",
    "        label, sentence = example\n",
    "        #LABEL_COUNTS\n",
    "        label_counts[label] += 1.0\n",
    "           \n",
    "        #word_counts\n",
    "        for word in sentence:\n",
    "            word_counts[label][word] += 1.0\n",
    "            word_total[label] += 1.0\n",
    "            \n",
    "    #LABEL_TOTAL\n",
    "    label_total = len(label_counts.keys())\n",
    "\n",
    "    return {'label_counts': label_counts, \n",
    "            'word_counts': word_counts, \n",
    "            'label_total': label_total, \n",
    "            'word_total': word_total}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "zctpzl72u1Yk",
    "outputId": "406edaad-053f-43e1-a64a-cab21f96ccc7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "140.0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_counts= count_words(data)['label_counts']\n",
    "word_counts= count_words(data)['word_counts']\n",
    "label_total= count_words(data)['label_total']\n",
    "word_total= count_words(data)['word_total']\n",
    "\n",
    "word_counts['__label__deu']['Ich']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6ZqGbeIxu3xN"
   },
   "outputs": [],
   "source": [
    "import operator\n",
    "def predict(sentence, mu, label_counts, word_counts, label_total, word_total):\n",
    "    '''\n",
    "     Parameters: \n",
    "        sentence (string): sentence to be classified\n",
    "        mu (positive real number): Laplace Smoothing hyperparameter\n",
    "        ** The other parameters introduced in the count_words function\n",
    "    \n",
    "    Returns:\n",
    "    best_label (string): the label that has the highest score. \n",
    "    \n",
    "    Implement the function to predict the best label for the given sentence using Naive Bayes algorithm \n",
    "    \n",
    "    '''\n",
    "    best_label = None\n",
    "    best_score = float('-inf')\n",
    "\n",
    "    label_outputs = defaultdict(lambda: 0)\n",
    "    for label in word_counts.keys():\n",
    "        score = 0.0\n",
    "        \n",
    "        sentence_count = len(word_counts[label].values())\n",
    "            \n",
    "        prod = 0\n",
    "        for i in sentence:\n",
    "            prod += np.log((word_counts[label][i]+mu)/(sentence_count+(mu*word_total[label])))\n",
    "            \n",
    "        lebel_prob = np.log(label_counts[label]/sum(list(label_counts.values())))\n",
    "            \n",
    "        \n",
    "        label_outputs[label] = prod +  lebel_prob\n",
    "        \n",
    "            \n",
    "    best_score = max(list(label_outputs.values()))\n",
    "    sorted_x = sorted(label_outputs.items(), key=operator.itemgetter(1))\n",
    "    best_label = sorted_x[-1][0]\n",
    "    \n",
    "    \n",
    "\n",
    "    return best_label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 212
    },
    "colab_type": "code",
    "id": "N2nETbC1u6Hu",
    "outputId": "80a1eee9-8197-4644-8d07-65b6cb9a794b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ich würde alles tun, um dich zu beschützen. __label__deu\n",
      "Tom ist an Kunst völlig uninteressiert. __label__deu\n",
      "Végeztem Tomival. __label__hun\n",
      "„Wird das in der Werkstatt gemacht?“ – „Nein, das muss an Ort und Stelle erledigt werden.“ __label__deu\n",
      "У меня есть яблоко. __label__rus\n",
      "Non possiamo lasciarle lì. __label__ita\n",
      "Том считает, что школа — это пустая трата времени. __label__rus\n",
      "My fathers don't speak Dutch. __label__hun\n",
      "El niño no sabe cómo comportarse. __label__spa\n",
      "Она думала, что он переночует у неё. __label__rus\n",
      "Helikopter neden kentin üstünde uçuyor? __label__hun\n"
     ]
    }
   ],
   "source": [
    "for example in range(len(data)):\n",
    "        label, sentence = data[example]\n",
    "        print(' '.join(sentence),predict(sentence, 3, label_counts, word_counts, label_total, word_total))\n",
    "        if example == 10:\n",
    "            break\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zonicOLbu8dV"
   },
   "outputs": [],
   "source": [
    "def compute_accuracy(valid_data, mu, counts):\n",
    "    '''\n",
    "    Parameters:\n",
    "    valid_data (list of tuples): returned value of load_data function \n",
    "    mu (positive real): Laplace smoothing hyper-parameter\n",
    "    counts (dictionary of dictionaries): return value of count_words_function\n",
    "    \n",
    "    Returns: \n",
    "    accuracy (float): the accuracy of the Naive Bayes classifier\n",
    "    '''\n",
    "    accuracy = 0.0\n",
    "    for label, sentence in valid_data:\n",
    "        predicted_label = predict(sentence, mu, label_counts, word_counts, label_total, word_total)\n",
    "        if predicted_label==label:\n",
    "            accuracy += 1.0\n",
    "         \n",
    "\n",
    "    return accuracy/len(valid_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 105
    },
    "colab_type": "code",
    "id": "r0CquAn2vBGp",
    "outputId": "bf7de242-93bd-49f0-efb8-4531aea32f07"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "** Naive Bayes **\n",
      "\n",
      "Training accuracy: 0.994\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\")\n",
    "print(\"** Naive Bayes **\")\n",
    "print(\"\")\n",
    "\n",
    "mu = 1.0\n",
    "train_data = load_data(\"train1.txt\")\n",
    "valid_data = load_data(\"valid1.txt\")\n",
    "counts = count_words(train_data)\n",
    "\n",
    "print(\"Training accuracy: %.3f\" % compute_accuracy(train_data, mu, counts))\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 105
    },
    "colab_type": "code",
    "id": "8eNLuajSvC_B",
    "outputId": "6d98ff7a-b1a1-4bda-d018-e011c5d4b933"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "** Naive Bayes **\n",
      "\n",
      "Validation accuracy: 0.947\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\")\n",
    "print(\"** Naive Bayes **\")\n",
    "print(\"\")\n",
    "\n",
    "mu = 1.0\n",
    "train_data = load_data(\"train1.txt\")\n",
    "valid_data = load_data(\"valid1.txt\")\n",
    "counts = count_words(valid_data)\n",
    "\n",
    "print(\"Validation accuracy: %.3f\" % compute_accuracy(valid_data, mu, counts))\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SAcVt9i3vWHw"
   },
   "source": [
    "<h1 style=\"font-family:verdana;font-size:150%;text-align:left;color:black\">***************************************************************</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h1 style=\"font-family:verdana;font-size:150%;text-align:left;color:blue\">Section 2: Softmax Classification of Text  </h1>\n",
    "\n",
    "##### In this part you'll implement a Softmax Classifier to classify the text (think of it as a 1 layer feedforward neural network). You need to build a model that predicts the langauge of the text given the words of the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_dict(filename, threshold=1):\n",
    "    '''\n",
    "    Parameters:\n",
    "    filename (string): path to the data file\n",
    "    \n",
    "    Returns:\n",
    "    word_dic: dictionary maps words to number of times it appeard in the corpus\n",
    "            dic {word: no of times word appears }\n",
    "    label_dic: dictionary maps labels to integers\n",
    "        dic {label: label_id}\n",
    "    '''\n",
    "    fin = io.open(filename, 'r', encoding='utf-8')\n",
    "    word_dict, label_dict = {}, {}\n",
    "    counts = defaultdict(lambda: 0)\n",
    "    for line in fin:\n",
    "        tokens = line.split()\n",
    "        label = tokens[0]\n",
    "\n",
    "        if not label in label_dict:\n",
    "            label_dict[label] = len(label_dict)\n",
    "\n",
    "        for w in tokens[1:]:\n",
    "            counts[w] += 1\n",
    "            \n",
    "    for k, v in counts.items():\n",
    "        if v > threshold:\n",
    "            word_dict[k] = len(word_dict)\n",
    "    return word_dict, label_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_dict, label_dict = build_dict('train1.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(filename, word_dict, label_dict):\n",
    "    '''\n",
    "    ## This function converts the text to a list of tuples of \n",
    "    [(label_id, word_representation),...]\n",
    "    \n",
    "    Parameters:\n",
    "    filename (string): path to the file which contains the data\n",
    "    word_dict (python dictionary): returned by build_dict() function above.\n",
    "    label_dict (python dictionary): reutrned by build_dict() function above() \n",
    "    \n",
    "    Returns:\n",
    "    data (list of tuples): \n",
    "    The representation of the data in the form \n",
    "    [(y_0, x_0, .. (y_i, x_i), ... (y_n, x_n))]\n",
    "    where y is the value of the class \n",
    "    x is the representation of the sentence as a word count vector \n",
    "    \n",
    "    '''\n",
    "    fin = io.open(filename, 'r', encoding='utf-8')\n",
    "    data = []\n",
    "    dim = len(word_dict)\n",
    "    for line in fin:\n",
    "        tokens = line.split()\n",
    "        label = tokens[0]\n",
    "\n",
    "        yi = label_dict[label]\n",
    "        xi = np.zeros(dim)\n",
    "        for word in tokens[1:]:\n",
    "            if word in word_dict:\n",
    "                wid = word_dict[word]\n",
    "                xi[wid] += 1.0\n",
    "        data.append((yi, xi))\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = load_data(\"train1.txt\", word_dict, label_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, array([1., 1., 1., ..., 0., 0., 0.])),\n",
       " (0, array([0., 0., 0., ..., 0., 0., 0.])),\n",
       " (1, array([0., 0., 0., ..., 0., 0., 0.])),\n",
       " (0, array([0., 0., 0., ..., 0., 0., 0.])),\n",
       " (2, array([0., 0., 0., ..., 0., 0., 0.]))]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(x):\n",
    "    '''\n",
    "    This function should apply softmax to vector x\n",
    "    \n",
    "    Parameter:\n",
    "    x (numpy array)\n",
    "    Returns: \n",
    "    softmax(x) (numpy array)\n",
    "    \n",
    "    '''\n",
    "    z = np.sum(np.exp(x-max(x)))\n",
    "    \n",
    "    return np.exp(x-max(x))/z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (Hint) Derivatives:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"font-family:verdana;font-size:150%;text-align:center;background-color:#f2f2f2;color:#993333; border:2px; border-style:solid; border-color:gray; padding: 1em\"> \n",
    "   Let $x_i$ be the input vector $W$ is the weight vector $m=$no. of labels, $n=$vocab size\n",
    "    $$ {\\bf S} = W × x_i $$  $x_{i} \\in R^{nx1} W \\in R^{m×n}$\n",
    "    $$  $$\n",
    "    $${\\bf O} = softmax(s) $$\n",
    "    $${\\bf L} = -log(O[y_{i}]) $$\n",
    "    $$  $$\n",
    "    $$\\frac{\\partial L}{\\partial W} = \\frac{\\partial L}{\\partial S} . \\frac{\\partial S}{\\partial W} $$\n",
    "    $$  $$\n",
    "    $ \\nabla L_{W} = (O-y_{true})$  x   $x_{i}^{T} $  \n",
    "    $$ (O-y_{true}) \\in R^{mx1}, x_{i}  \\in R^{nx1}$$\n",
    "\n",
    "</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sgd(w, data, niter):\n",
    "    '''\n",
    "    This function should perform the Stochastic Gradient Descent algorithm \n",
    "    \n",
    "    Parameter:\n",
    "    w (numpy array): weight vector\n",
    "    data (list of tuples): [...(y_i, x_i)...] from above\n",
    "    niter (int): number of iterations\n",
    "    \n",
    "    Retunrs:\n",
    "    w (numpy array): weight vector after training\n",
    "    '''\n",
    "    nlabels, dim = w.shape\n",
    "    for iter in range(niter):\n",
    "        for label,x in data:\n",
    "            \n",
    "            one_hot_label = np.eye(nlabels)[label]\n",
    "            \n",
    "            s = np.dot(w,x)\n",
    "            o = softmax(s)\n",
    "            l = -np.log(o)\n",
    "\n",
    "            d_l = (o - one_hot_label).reshape(-1,1)*x.reshape(-1,1).T\n",
    "            \n",
    "            w = w - 0.1*d_l\n",
    "    return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(w, x):\n",
    "    '''\n",
    "    This function should compute and return the prediction. \n",
    "    Parameters:\n",
    "    w (numpy array): trained weight vector\n",
    "    x (numpy array): word count vector\n",
    "    \n",
    "    Returns: \n",
    "    prediction (int): index of the correct prediction (y_i)\n",
    "    '''\n",
    "    return np.argmax(np.dot(w,x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_accuracy(w, valid_data):\n",
    "    '''\n",
    "    This function should compute the accuracy of the classifier \n",
    "    Parameters:\n",
    "    w (numpy array): trained weight vector\n",
    "    valid_data (list of tuples): loaded validation data using load_data() function \n",
    "    \n",
    "    Returns: \n",
    "    accuracy (float): accuracy of the classifier \n",
    "    '''\n",
    "    accuracy = 0.0\n",
    "    for label,x in valid_data:\n",
    "        new_label = predict(w,x)\n",
    "        if new_label==label:\n",
    "            accuracy += 1.0\n",
    "\n",
    "    return accuracy/len(valid_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "** Logistic Regression **\n",
      "\n",
      "\n",
      "Validation accuracy: 0.929\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\")\n",
    "print(\"** Logistic Regression **\")\n",
    "print(\"\")\n",
    "\n",
    "word_dict, label_dict = build_dict(\"train1.txt\")\n",
    "train_data = load_data(\"train1.txt\", word_dict, label_dict)\n",
    "valid_data = load_data(\"valid1.txt\", word_dict, label_dict)\n",
    "\n",
    "nlabels = len(label_dict)\n",
    "dim = len(word_dict)\n",
    "w = np.zeros([nlabels, dim])\n",
    "w = sgd(w, train_data, 20)\n",
    "print(\"\")\n",
    "print(\"Validation accuracy: %.3f\" % compute_accuracy(w, valid_data))\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Language detection",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
